{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q prettytable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from prettytable import PrettyTable\n",
                "\n",
                "\n",
                "def count_parameters(model):\n",
                "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
                "    total_params = 0\n",
                "    for name, parameter in model.named_parameters():\n",
                "        if not parameter.requires_grad:\n",
                "            continue\n",
                "        params = parameter.numel()\n",
                "        table.add_row([name, params])\n",
                "        total_params += params\n",
                "    print(table)\n",
                "    print(f\"Total Trainable Params: {total_params}\")\n",
                "    return total_params"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "# onnx for network architecture visualization\n",
                "import onnx\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torchvision\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+------------+------------+\n",
                        "|  Modules   | Parameters |\n",
                        "+------------+------------+\n",
                        "| fc1.weight |  1572864   |\n",
                        "|  fc1.bias  |    512     |\n",
                        "| fc2.weight | 301989888  |\n",
                        "|  fc2.bias  |   16384    |\n",
                        "| fc3.weight |  67108864  |\n",
                        "|  fc3.bias  |    4096    |\n",
                        "| fc4.weight |   204800   |\n",
                        "|  fc4.bias  |     50     |\n",
                        "| bn4.weight |     50     |\n",
                        "|  bn4.bias  |     50     |\n",
                        "+------------+------------+\n",
                        "Total Trainable Params: 370897558\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "370897558"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from JigsawNet import JigsawNet\n",
                "\n",
                "model = JigsawNet(n_classes=50, num_features=3072, relu_in_last_fc=True)\n",
                "count_parameters(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_input = torch.randn(1, 36, 3072)\n",
                "input_names = [\"dummy_input\"]\n",
                "output_names = [\"dummy_output\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
                        "verbose: False, log level: Level.ERROR\n",
                        "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "onnx_path = \"results/onnx_JigsawNet.pt\"\n",
                "torch.onnx.export(\n",
                "    model, dummy_input, onnx_path, input_names=input_names, output_names=output_names\n",
                ")\n",
                "onnx.save(onnx.shape_inference.infer_shapes(onnx.load(onnx_path)), onnx_path)\n",
                "# Then go to netron.app in your browser and choose the exported file to visualize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+------------+------------+\n",
                        "|  Modules   | Parameters |\n",
                        "+------------+------------+\n",
                        "| fc1.weight |  75497472  |\n",
                        "|  fc1.bias  |    1024    |\n",
                        "| fc2.weight |   524288   |\n",
                        "|  fc2.bias  |    512     |\n",
                        "| fc3.weight |   65536    |\n",
                        "|  fc3.bias  |    128     |\n",
                        "| fc4.weight |    6400    |\n",
                        "|  fc4.bias  |     50     |\n",
                        "| bn4.weight |     50     |\n",
                        "|  bn4.bias  |     50     |\n",
                        "+------------+------------+\n",
                        "Total Trainable Params: 76095510\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "76095510"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# code from TA\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "\n",
                "# # Define the model architecture\n",
                "class JigsawModel(nn.Module):\n",
                "    def __init__(self, num_positions):\n",
                "        super(JigsawModel, self).__init__()\n",
                "        self.num_positions = num_positions\n",
                "        self.fc1 = nn.Linear(36 * 2048, 1024)\n",
                "        self.fc2 = nn.Linear(1024, 512)\n",
                "        self.fc3 = nn.Linear(512, 128)\n",
                "        self.fc4 = nn.Linear(128, 50)\n",
                "        self.bn4 = nn.BatchNorm1d(50)  # Batch normalization after fc4\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = x.view(-1, 36 * 2048)\n",
                "        x = F.relu(self.fc1(x))\n",
                "        x = F.relu(self.fc2(x))\n",
                "        x = F.relu(self.fc3(x))\n",
                "        x = F.relu(\n",
                "            self.bn4(self.fc4(x))\n",
                "        )  # Apply batch normalization after fc4 and before activation\n",
                "        x = F.softmax(x, dim=1)\n",
                "        return x\n",
                "\n",
                "\n",
                "model = JigsawModel(num_positions=50)\n",
                "count_parameters(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "dummy_input = torch.randn(1, 36, 2048)\n",
                "input_names = [\"dummy_input\"]\n",
                "output_names = [\"dummy_output\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
                        "verbose: False, log level: Level.ERROR\n",
                        "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "onnx_path = \"results/onnx_JigsawModel.pt\"\n",
                "torch.onnx.export(\n",
                "    model, dummy_input, onnx_path, input_names=input_names, output_names=output_names\n",
                ")\n",
                "onnx.save(onnx.shape_inference.infer_shapes(onnx.load(onnx_path)), onnx_path)\n",
                "# Then go to netron.app in your browser and choose the exported file to visualize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
                        "verbose: False, log level: Level.ERROR\n",
                        "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from JigsawNet import JigsawNet\n",
                "\n",
                "model = JigsawNet(\n",
                "    n_classes=50, num_features=2048, relu_in_last_fc=True, include_softmax=True\n",
                ")\n",
                "\n",
                "onnx_path = \"results/onnx_JigsawNet_2048.pt\"\n",
                "torch.onnx.export(\n",
                "    model, dummy_input, onnx_path, input_names=input_names, output_names=output_names\n",
                ")\n",
                "onnx.save(onnx.shape_inference.infer_shapes(onnx.load(onnx_path)), onnx_path)\n",
                "# Then go to netron.app in your browser and choose the exported file to visualize\n",
                "\n",
                "pytorch_total_params = sum(p.numel() for p in model.parameters())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "370373270"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pytorch_total_params"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+------------+------------+\n",
                        "|  Modules   | Parameters |\n",
                        "+------------+------------+\n",
                        "| fc1.weight |  1048576   |\n",
                        "|  fc1.bias  |    512     |\n",
                        "| fc2.weight | 301989888  |\n",
                        "|  fc2.bias  |   16384    |\n",
                        "| fc3.weight |  67108864  |\n",
                        "|  fc3.bias  |    4096    |\n",
                        "| fc4.weight |   204800   |\n",
                        "|  fc4.bias  |     50     |\n",
                        "| bn4.weight |     50     |\n",
                        "|  bn4.bias  |     50     |\n",
                        "+------------+------------+\n",
                        "Total Trainable Params: 370373270\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "370373270"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "count_parameters(model)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bigger Model without Softmax Doesn't Work"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "\n",
                "def calc_accuracy(ground_truth_file, result_file):\n",
                "    groud_truth = pd.read_csv(ground_truth_file, header=None)\n",
                "    result = pd.read_csv(result_file, header=None)\n",
                "    acc = 1 - len(result.compare(groud_truth)) / len(groud_truth)\n",
                "    return acc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.31920710868079294"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "acc = calc_accuracy(\"../cs712-phuong/ensemble_test.txt\", \"./data/test.txt\")\n",
                "acc"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Use Phuong's Methodology\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 1.16 s, sys: 284 ms, total: 1.45 s\n",
                        "Wall time: 1min 41s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "!python train_v9.py > logs/v9-e-300-b-16-f-20-lr-0.0001-step-182-train.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 52.3 ms, sys: 19.6 ms, total: 71.9 ms\n",
                        "Wall time: 5 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "!python validate-timm.py -n test > logs/v9-e-300-b-16-f-20-lr-0.0001-step-182-test.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.9432672590567327"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "acc = calc_accuracy(\"./results/ensemble_test.txt\", \"./data/test.txt\")\n",
                "acc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.4313055365686944"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "acc = calc_accuracy(\"./results/test.txt\", \"./data/test.txt\")\n",
                "acc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 67.8 ms, sys: 692 µs, total: 68.5 ms\n",
                        "Wall time: 4.82 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "\n",
                "!python validate-timm.py > logs/v9-e-300-b-16-f-20-lr-0.0001-step-182-val.txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.44542974079126874"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "acc = calc_accuracy(\"./results/validation.txt\", \"./data/validation.txt\")\n",
                "acc"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
